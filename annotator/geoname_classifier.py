
# This script was generated by the train.py script in EHA's private eval-scripts
# repository.

import numpy as np
from numpy import array, int32
base_classifier = {'C': 1.0,
 'class_weight': None,
 'classes_': array([False,  True], dtype=bool),
 'coef_': array([[ 0.37180698,  0.01100534, -0.01791225,  0.32988536,  0.7161249 ,
         0.57423449, -0.42578113, -0.00327976, -2.28480914, -2.15707205,
         0.07198946, -2.4725377 ,  0.        ,  0.        ,  0.        ,
         0.        ,  0.        ]]),
 'dual': False,
 'fit_intercept': True,
 'intercept_': array([-6.84242943]),
 'intercept_scaling': 1,
 'max_iter': 100,
 'multi_class': 'ovr',
 'n_iter_': 37,
 'penalty': 'l2',
 'random_state': None,
 'solver': 'liblinear',
 'tol': 0.0001,
 'verbose': 0}
HIGH_CONFIDENCE_THRESHOLD = 0.5
GEONAME_SCORE_THRESHOLD = 0.1
contextual_classifier = {'C': 1.0,
 'class_weight': None,
 'classes_': array([False,  True], dtype=bool),
 'coef_': array([[  2.68181061e-01,   1.13354256e-02,  -5.52340542e-02,
          1.91595796e-01,   2.64518222e-01,   2.52988071e-02,
         -2.15483841e-01,  -2.01892945e-03,  -2.07169279e+00,
         -2.00969282e+00,   2.35505470e-01,  -2.16638807e+00,
          7.66801512e-01,   1.25186716e-01,   7.08104607e-01,
         -3.75100676e-01,   1.54620223e+00]]),
 'dual': False,
 'fit_intercept': True,
 'intercept_': array([-6.01226822]),
 'intercept_scaling': 1,
 'max_iter': 100,
 'multi_class': 'ovr',
 'n_iter_': 30,
 'penalty': 'l2',
 'random_state': None,
 'solver': 'liblinear',
 'tol': 0.0001,
 'verbose': 0}
# Logistic regression code from scipy
def predict_proba(X, classifier):
    """Probability estimation for OvR logistic regression.
    Positive class probabilities are computed as
    1. / (1. + np.exp(-classifier.decision_function(X)));
    multiclass is handled by normalizing that over all classes.
    """
    prob = np.dot(X, classifier['coef_'].T) + classifier['intercept_']
    prob = prob.ravel() if prob.shape[1] == 1 else prob
    prob *= -1
    np.exp(prob, prob)
    prob += 1
    np.reciprocal(prob, prob)
    if prob.ndim == 1:
        return np.vstack([1 - prob, prob]).T
    else:
        # OvR normalization, like LibLinear's predict_probability
        prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))
        return prob
def predict_proba_base(X):
    return predict_proba(X, base_classifier)
def predict_proba_contextual(X):
    return predict_proba(X, contextual_classifier)
